---
layout:     post
title:      集成学习
subtitle:   
date:       2019-09-01
author:     YY
header-img: img/post-bg-rwd.jpg
catalog: true
tags:
    - 机器学习
    - 集成学习
---

## 集成学习   

集成方法是将几种机器学习技术组合成一个预测模型的元算法，以达到减小方差（bagging）、偏差（boosting）或改进预测（stacking）的效果。
1. Bagging使用装袋采样来获取数据子集训练基础学习器。通常分类任务使用投票的方式集成，而回归任务通过平均的方式集成。
2. boosting的主要原则是训练一系列的弱学习器，训练的方式是利用加权的数据，在训练的早期对于错分数据给予较大的权重。如果是分类任务按照权重进行投票，而对于回归任务进行加权，然后再进行预测。
3. Stacking是通过一个元分类器或者元回归器来整合多个分类模型或回归模型的集成学习技术。基础模型利用整个训练集做训练，元模型将基础模型的特征作为特征进行训练。

### **感谢你耐心的阅读！ ( * ^ _ ^ * )**